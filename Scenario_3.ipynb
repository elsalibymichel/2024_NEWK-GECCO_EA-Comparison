{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtsKGNBNgNLx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import io\n",
        "from io import BytesIO\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import matplotlib_inline.backend_inline\n",
        "\n",
        "import statistics\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHyCAxWQ89Fs"
      },
      "outputs": [],
      "source": [
        "# Specify the \"Colab Notebooks\" subfolder of the Google Driver directory that contains the data of your experiment\n",
        "## If you want to work directly in the \"Colba Notebooks\" directory, leave the '' brackets empty\n",
        "colab_sub_folder = '/ERAL Lab/Paper 001/Reproducibility Folder'\n",
        "\n",
        "# Specify the string to begin the names of the generated files\n",
        "experiment_name = 'Scenario_3'\n",
        "\n",
        "# Specify the name of the .csv file containing the data to be processed and its separator character\n",
        "file_name = experiment_name + '.csv'\n",
        "separator = ';'\n",
        "\n",
        "\n",
        "# Specify the interval for \"evals\" quantization\n",
        "delta_quantization = 100\n",
        "\n",
        "# Set alpha for wilcoxon test\n",
        "level_significance = 0.01\n",
        "\n",
        "# Set the efficiency percentile reference\n",
        "efficiency_percentile_reference = 0.75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcDDumT5xXkC"
      },
      "outputs": [],
      "source": [
        "# Mount drive\n",
        "drive.mount('/content/drive')\n",
        "directory = 'drive/MyDrive/Colab Notebooks' + colab_sub_folder\n",
        "%cd {directory}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8joF94P-yUk"
      },
      "outputs": [],
      "source": [
        "# Read the .csv with the data\n",
        "fileCSV = pd.read_csv(file_name, sep = separator)\n",
        "fileCSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYBHhZJQoxXR"
      },
      "outputs": [],
      "source": [
        "# Change some column names and create some new columns for code clarity\n",
        "\n",
        "fileCSV['solver'] = fileCSV['solver_sigma'].str.split('-').str[0]\n",
        "\n",
        "fileCSV['sigma'] = fileCSV['solver_sigma'].str.split('-').str[1]\n",
        "fileCSV['sigma'] = np.where(fileCSV['sigma'].isna(), fileCSV['solver'], fileCSV['sigma'])\n",
        "\n",
        "\n",
        "fileCSV['solver_sigma_seed'] = fileCSV['solver_sigma'] + \"_seed:\" + fileCSV['seed'].astype(str)\n",
        "\n",
        "fileCSV['objective'] = \"minimize\"\n",
        "\n",
        "fileCSV.rename(columns={'best→control.quality': 'best_fitness'}, inplace=True)\n",
        "\n",
        "fileCSV['evals_quantized'] = fileCSV['evals'].astype(int) // delta_quantization\n",
        "\n",
        "fileCSV.rename(columns={'best→genotype→size': 'genotype_size'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1D-Vj1OXCOW"
      },
      "outputs": [],
      "source": [
        "united_CSV = fileCSV.copy()\n",
        "united_CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htbVu_i-blqm"
      },
      "outputs": [],
      "source": [
        "# Create a list of all different problems, solvers, sigmas, solvers_sigmas, seeds, solvers_sigmas_seeds\n",
        "\n",
        "problems = sorted(united_CSV['problem'].drop_duplicates().tolist())\n",
        "solvers = sorted(united_CSV['solver'].drop_duplicates().tolist())\n",
        "sigmas = sorted(united_CSV['sigma'].drop_duplicates().tolist())\n",
        "solvers_sigmas = sorted(united_CSV['solver_sigma'].drop_duplicates().tolist())\n",
        "seeds = sorted(united_CSV['seed'].drop_duplicates().tolist())\n",
        "solvers_sigmas_seeds = sorted(united_CSV['solver_sigma_seed'].drop_duplicates().tolist())\n",
        "\n",
        "print('{:15s}{} {}'.format('problems', ':', problems))\n",
        "print('{:15s}{} {}'.format('solvers', ':', solvers))\n",
        "print('{:15s}{} {}'.format('sigmas', ':', sigmas))\n",
        "print('{:15s}{} {}'.format('solvers_sigmas', ':', solvers_sigmas))\n",
        "print('{:15s}{} {}'.format('seeds', ':', seeds))\n",
        "print('{:15s}{} {}'.format('solver_sigma_seed', ':', solvers_sigmas_seeds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAfgnp2tc4uZ"
      },
      "outputs": [],
      "source": [
        "# Images style settings\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
        "plt.rcParams.update({'font.size': 6, \"lines.linewidth\": 0.1})\n",
        "\n",
        "# Set colormap\n",
        "color_map = mpl.colormaps['tab10']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfKTUCKlNuKq"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Convergence plots\n",
        "\n",
        "# Some image settings\n",
        "fig, axs = plt.subplots(len(problems), len(solvers), sharex=True, sharey='row', layout='constrained', figsize=(2.2*len(solvers), len(problems)))\n",
        "fig.suptitle('Convergence plots', fontsize=12, fontweight='bold')\n",
        "fig.supxlabel('x = Evals', fontsize=8, fontweight='bold')\n",
        "fig.supylabel('y = Best Fitness', fontsize=8, fontweight='bold')\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  # Specify the \"problem\" to the right of each row of plots\n",
        "  axs[i, len(solvers)-1].yaxis.set_label_position(\"right\")\n",
        "  axs[i, len(solvers)-1].set_ylabel(problem, rotation='horizontal', labelpad=10, horizontalalignment='left')\n",
        "\n",
        "  # Filter rows of the current problem\n",
        "  pre_pre_filtered_data = united_CSV[united_CSV['problem'] == problem]\n",
        "\n",
        "  for j, solver in enumerate(solvers):\n",
        "\n",
        "    # Specify the \"solver\" at the top of plots\n",
        "    axs[0, j].set_title(solver, pad=10, rotation=10, weight='bold')\n",
        "\n",
        "    colors = color_map.colors\n",
        "\n",
        "    # Filter rows of the current solver (and problem)\n",
        "    pre_filtered_data = pre_pre_filtered_data[pre_pre_filtered_data['solver'] == solver]\n",
        "\n",
        "    for sigma_index, sigma in enumerate(sigmas):\n",
        "\n",
        "      color = colors[sigma_index % len(colors)]\n",
        "\n",
        "      # Filter rows of the current simga (and solver and problem)\n",
        "      filtered_data = pre_filtered_data[pre_filtered_data['sigma'] == sigma]\n",
        "\n",
        "      # Not all solvers has all values of sigma\n",
        "      if filtered_data.empty:\n",
        "        continue\n",
        "\n",
        "      # Group the filtered data according to \"evals\"\n",
        "      grouped_data = filtered_data.groupby('evals_quantized')['best_fitness'].describe()[['25%', '50%', '75%']]\n",
        "      evals_quantized = grouped_data.index\n",
        "\n",
        "      # Calculate quartiles\n",
        "      median = grouped_data['50%']\n",
        "      q1 = grouped_data['25%']\n",
        "      q3 = grouped_data['75%']\n",
        "\n",
        "      # Rescale \"evals_quantized\" by \"delta_quantization\"\n",
        "      evals = evals_quantized * delta_quantization\n",
        "\n",
        "      # Plot the median values in the plot of section \"[i,j]\"\n",
        "      axs[i, j].scatter(evals, median, marker='o', s=0.05, color=color, label=sigma)\n",
        "\n",
        "      # Connect the dots\n",
        "      axs[i, j].plot(evals, median, color=color)\n",
        "\n",
        "      # Add shadows representing the area between first and third quartile\n",
        "      axs[i, j].fill_between(evals, q1, q3, color=color, alpha=0.1)\n",
        "\n",
        "# Add a single legend on the \"center right\" of the figure\n",
        "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
        "legend_elements = [Line2D([0], [0], color=color_map.colors[i % len(color_map.colors)], lw=2, label=sigma) for i, sigma in enumerate(sigmas)]\n",
        "legend = fig.legend(handles=legend_elements, loc='center right')\n",
        "legend.set_title(\"Sigma\")\n",
        "\n",
        "# Save image\n",
        "plt.savefig('Figures/' + experiment_name + \"/\" + experiment_name + '_Convergence.png', bbox_inches='tight', transparent=False, dpi=600)\n",
        "\n",
        "# Display image\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDB_q1s-lk2G"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Effectiveness boxplots\n",
        "\n",
        "# Some image settings\n",
        "fig, axs = plt.subplots(1, len(problems), sharex=False, sharey=True, layout='constrained', figsize=(2*len(problems), 0.5*len(solvers)))\n",
        "fig.suptitle('Effectiveness plots', fontsize=12, fontweight='bold')\n",
        "fig.supxlabel('x = Best Fitness', fontsize=8, fontweight='bold')\n",
        "big_title = experiment_name + \"_EffectiveMatrix_\"\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  # Specify the \"problem\" of each set of boxplots\n",
        "  axs[i].set_title(problem, pad=10, weight='bold')\n",
        "\n",
        "  # Collect data for each solver_sigma\n",
        "  data_to_plot = []\n",
        "  labels = []\n",
        "\n",
        "  # Filter rows of the current problem\n",
        "  pre_pre_filtered_data = united_CSV[united_CSV['problem'] == problem]\n",
        "\n",
        "  for j, solver_sigma in enumerate(solvers_sigmas):\n",
        "\n",
        "    # Filter the data for the current problem and solver_sigma\n",
        "    pre_filtered_data = pre_pre_filtered_data[pre_pre_filtered_data['solver_sigma'] == solver_sigma]\n",
        "\n",
        "    # Not all solvers has all values of sigma\n",
        "    if pre_filtered_data.empty:\n",
        "      continue\n",
        "\n",
        "    # Find the maximum number of evaluations\n",
        "    max_eval = pre_filtered_data['evals'].max()\n",
        "\n",
        "    # Filter the data to only include the rows with the maximum number of evaluations\n",
        "    filtered_data = pre_filtered_data[pre_filtered_data['evals'] == max_eval]\n",
        "\n",
        "    # Append the 'best_fitness' data for the current solver_sigma to the list\n",
        "    data_to_plot.append(filtered_data['best_fitness'].tolist())\n",
        "    labels.append(solver_sigma)\n",
        "\n",
        "  # Create the boxplot for the current problem\n",
        "  bp = axs[i].boxplot(data_to_plot, patch_artist=True, vert=False)\n",
        "\n",
        "  # Save data for LaTeX plots\n",
        "  data_to_plot_transposed = list(map(list, zip(*data_to_plot)))\n",
        "  df = pd.DataFrame(data_to_plot_transposed, columns=solvers_sigmas)\n",
        "  df.to_csv(\"LaTeX/\" + experiment_name + \"/\" + big_title + problem + '.txt', sep='\\t', index=False)\n",
        "\n",
        "\n",
        "  # Set the colors of the boxplot using the color map\n",
        "  for patch, color in zip(bp['boxes'], color_map.colors[:len(solvers_sigmas)]):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "  # Set the positions and labels of the y-ticks\n",
        "  axs[i].set_yticks(range(1, len(labels) + 1))\n",
        "  axs[i].set_yticklabels(labels)\n",
        "\n",
        "# Saving image\n",
        "plt.savefig('Figures/' + experiment_name + \"/\" + experiment_name + '_Effectiveness.png', bbox_inches='tight', transparent=False, dpi=600)\n",
        "\n",
        "# Display image\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data to get only the last evaluation of each tuple (problem, solver, sigma, seed)\n",
        "last_evals_df = united_CSV[united_CSV.groupby(['problem', 'solver_sigma_seed'])['evals'].transform(max) == united_CSV['evals']]"
      ],
      "metadata": {
        "id": "o1VIO6OJHGbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi9zvBzl7yVm"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Number of victories score\n",
        "\n",
        "# DataFrame for saving the binary effectiveness based on Wilcoxon's test (best vs other, pairwise)\n",
        "binary_ranking_effectiveness_df = pd.DataFrame(index=problems, columns=solvers_sigmas)\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  # Filter the last evaluations of that problem\n",
        "  filtered_data = last_evals_df[last_evals_df['problem']==problem]\n",
        "\n",
        "  # Set the objective\n",
        "  objective = filtered_data['objective'].iloc[0]\n",
        "\n",
        "  # Check if is a max or min problem\n",
        "  if objective == 'minimize':\n",
        "    ascending = True\n",
        "  elif objective == 'maximize':\n",
        "    ascending = False\n",
        "  else:\n",
        "    raise ValueError('\\\"task_objective\\\" can be only \\\"minimize\\\" or \\\"maximize\\\"')\n",
        "\n",
        "  # Compute the median effectiveness of each solver_sigma for the considered problem\n",
        "  median_data = filtered_data.groupby('solver_sigma').median('best_fitness').sort_values('best_fitness', ascending=ascending)\n",
        "\n",
        "  # Set the best solver_sigma for the considered problem\n",
        "  best_solver_sigma = median_data.index[0]\n",
        "  best_solver_sigma_df = filtered_data[filtered_data['solver_sigma']==best_solver_sigma]['best_fitness']\n",
        "\n",
        "  # For each solver_sigma\n",
        "  for j, solver_sigma in enumerate(solvers_sigmas):\n",
        "\n",
        "    # If the current solver_sigma is the best, set its binary_ranking = 1\n",
        "    if best_solver_sigma == solver_sigma:\n",
        "      binary_ranking_effectiveness_df.at[problem, solver_sigma] = 1\n",
        "      continue\n",
        "\n",
        "    # For the others solvers_sigmas, filter\n",
        "    other_solver_sigma_df = filtered_data[filtered_data['solver_sigma']==solver_sigma]['best_fitness']\n",
        "\n",
        "    # For the other solvers_sigmas, perform the Wilcoxon test\n",
        "    statistiche, p_value = wilcoxon(best_solver_sigma_df, other_solver_sigma_df)\n",
        "\n",
        "    # Check p-value\n",
        "    if p_value > level_significance:\n",
        "      # No significant difference, so binary_rankin = 1\n",
        "      binary_ranking_effectiveness_df.at[problem, solver_sigma] = 1\n",
        "    else:\n",
        "      # There is a significant difference, so binary_rankin = 0\n",
        "      binary_ranking_effectiveness_df.at[problem, solver_sigma] = 0\n",
        "\n",
        "# Compute the binary score\n",
        "binary_score_effectiveness = binary_ranking_effectiveness_df.sum()\n",
        "binary_score_effectiveness.name = \"NOVS\"\n",
        "binary_ranking_df = pd.concat([binary_ranking_effectiveness_df, binary_score_effectiveness.to_frame().T])\n",
        "\n",
        "# Save results in an xlsx file\n",
        "binary_ranking_df.to_excel(\"XLSX Files/\" + experiment_name + \"/\" + experiment_name + \"_NOVS.xlsx\")\n",
        "\n",
        "# Visualize binary scores\n",
        "print(\"          NOVS:\\n\")\n",
        "print(binary_ranking_df.loc['NOVS'].sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Number of victories score\n",
        "\n",
        "# DataFrame for saving the binary effectiveness based on Wilcoxon's test (best vs other, pairwise)\n",
        "binary_ranking_effectiveness_df = pd.DataFrame(index=problems, columns=solvers_sigmas)\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  # Filter the last evaluations of that problem\n",
        "  filtered_data = last_evals_df[last_evals_df['problem']==problem]\n",
        "\n",
        "  # Set the objective\n",
        "  objective = filtered_data['objective'].iloc[0]\n",
        "\n",
        "  # Check if is a max or min problem\n",
        "  if objective == 'minimize':\n",
        "    ascending = True\n",
        "  elif objective == 'maximize':\n",
        "    ascending = False\n",
        "  else:\n",
        "    raise ValueError('\\\"task_objective\\\" can be only \\\"minimize\\\" or \\\"maximize\\\"')\n",
        "\n",
        "  # Compute the mean effectiveness of each solver_sigma for the considered problem\n",
        "  mean_data = filtered_data.groupby('solver_sigma').mean('best_fitness').sort_values('best_fitness', ascending=ascending)\n",
        "\n",
        "  # Set the best solver_sigma for the considered problem\n",
        "  best_solver_sigma = mean_data.index[0]\n",
        "  best_solver_sigma_df = filtered_data[filtered_data['solver_sigma']==best_solver_sigma]['best_fitness']\n",
        "\n",
        "  # For each solver_sigma\n",
        "  for j, solver_sigma in enumerate(solvers_sigmas):\n",
        "\n",
        "    # If the current solver_sigma is the best, set its binary_ranking = 1\n",
        "    if best_solver_sigma == solver_sigma:\n",
        "      binary_ranking_effectiveness_df.at[problem, solver_sigma] = 1\n",
        "      continue\n",
        "\n",
        "    # For the others solvers_sigmas, filter\n",
        "    other_solver_sigma_df = filtered_data[filtered_data['solver_sigma']==solver_sigma]['best_fitness']\n",
        "\n",
        "    # For the other solvers_sigmas, perform the Wilcoxon test\n",
        "    statistiche, p_value = wilcoxon(best_solver_sigma_df, other_solver_sigma_df)\n",
        "\n",
        "    # Check p-value\n",
        "    if p_value > level_significance:\n",
        "      # No significant difference, so binary_rankin = 1\n",
        "      binary_ranking_effectiveness_df.at[problem, solver_sigma] = 1\n",
        "    else:\n",
        "      # There is a significant difference, so binary_rankin = 0\n",
        "      binary_ranking_effectiveness_df.at[problem, solver_sigma] = 0\n",
        "\n",
        "# Compute the binary score\n",
        "binary_score_effectiveness = binary_ranking_effectiveness_df.sum()\n",
        "binary_score_effectiveness.name = \"NOVS\"\n",
        "binary_ranking_df = pd.concat([binary_ranking_effectiveness_df, binary_score_effectiveness.to_frame().T])\n",
        "\n",
        "# Save results in an xlsx file\n",
        "binary_ranking_df.to_excel(\"XLSX Files/\" + experiment_name + \"/\" + experiment_name + \"_NOVS.xlsx\")\n",
        "\n",
        "# Visualize binary scores\n",
        "print(\"          NOVS:\\n\")\n",
        "print(binary_ranking_df.loc['NOVS'].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "xkmrKiq61FJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcGybsy5w8ar"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Normalized effectiveness ranking boxplots\n",
        "\n",
        "# Rank (solver, sigma, seed) tuples by their effectiveness\n",
        "effectiveness_ranking = np.full((len(problems), len(solvers_sigmas_seeds)), '', dtype=object)\n",
        "\n",
        "# Store rankings on the fixed problem obtained by each cuple (solver, sigma)\n",
        "solvers_sigmas__rankings = [[] for _ in range(len(solvers_sigmas))]\n",
        "\n",
        "# Compute the normalization factor (the largest possible rank that can be obtained)\n",
        "normalization_factor = len(solvers_sigmas) * len(seeds)\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  filtered_data = last_evals_df[last_evals_df['problem']==problem]\n",
        "\n",
        "  objective = filtered_data['objective'].iloc[0]\n",
        "\n",
        "  # Check if is a max or min problem\n",
        "  if objective == 'minimize':\n",
        "    ascending = True\n",
        "  elif objective == 'maximize':\n",
        "    ascending = False\n",
        "  else:\n",
        "    raise ValueError('\\\"task_objective\\\" can be only \\\"minimize\\\" or \\\"maximize\\\"')\n",
        "\n",
        "  # Sort data\n",
        "  sorted_data = filtered_data.sort_values('best_fitness', ascending=ascending)\n",
        "\n",
        "  for j in range(len(solvers_sigmas_seeds)):\n",
        "\n",
        "    # Rank (solver, sigma, seed) tuples by their effectiveness\n",
        "    solver_sigma_seed = sorted_data['solver_sigma_seed'].iloc[j]\n",
        "\n",
        "    solver_sigma = filtered_data[filtered_data['solver_sigma_seed'] == solver_sigma_seed]['solver_sigma'].iloc[0]\n",
        "\n",
        "    # Store rankings obtained for each tuple\n",
        "    index = solvers_sigmas.index(solver_sigma)\n",
        "    solvers_sigmas__rankings[index].append((j + 1) / normalization_factor)\n",
        "\n",
        "# Create the boxplot for the current problem\n",
        "plt.figure()\n",
        "bp = plt.boxplot(solvers_sigmas__rankings, patch_artist=True, vert=False, labels=solvers_sigmas)\n",
        "\n",
        "# Save data for latex\n",
        "data_to_plot_transposed = list(map(list, zip(*solvers_sigmas__rankings)))\n",
        "df = pd.DataFrame(data_to_plot_transposed, columns=solvers_sigmas)\n",
        "df.to_csv(\"LaTeX/\" + experiment_name + \"/\" + \"AAA_\" + experiment_name + \"_NER\" + '.txt', sep='\\t', index=False)\n",
        "\n",
        "# Set the colors of the boxplot using the color map\n",
        "for patch, color in zip(bp['boxes'], color_map.colors[:len(solvers_sigmas)]):\n",
        "  patch.set_facecolor(color)\n",
        "\n",
        "# Save image\n",
        "plt.savefig(\"Figures/\" + experiment_name + \"/\" + experiment_name + '_NER.png', bbox_inches='tight', transparent=False, dpi=600)\n",
        "\n",
        "# Display image\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Efficiency boxplots\n",
        "\n",
        "best_fitnesses_percentile = []\n",
        "\n",
        "# Store rankings on the fixed problem obtained by each cuple (solver, sigma)\n",
        "solvers_sigmas__first_eval_to_hit_threshold = [[] for _ in range(len(solvers_sigmas))]\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  current_problem_last_evals_df = last_evals_df[last_evals_df['problem']==problem].reset_index(drop=True)\n",
        "\n",
        "  objective = current_problem_last_evals_df['objective'].iloc[0]\n",
        "\n",
        "  # Check if is a max or min problem\n",
        "  if objective == 'minimize':\n",
        "    ascendingg = True\n",
        "  elif objective == 'maximize':\n",
        "    ascendingg = False\n",
        "  else:\n",
        "    raise ValueError('\\\"task_objective\\\" can be only \\\"minimize\\\" or \\\"maximize\\\"')\n",
        "\n",
        "  # Sort data\n",
        "  sorted_data = current_problem_last_evals_df.sort_values('best_fitness', ascending=ascendingg)\n",
        "\n",
        "  current_index_percentile = int(efficiency_percentile_reference * len(sorted_data))\n",
        "  current_problem_best_fitness_percentile = sorted_data.iloc[current_index_percentile]['best_fitness']\n",
        "\n",
        "  best_fitnesses_percentile.append(current_problem_best_fitness_percentile)\n",
        "\n",
        "  problem_filtered_data = united_CSV[(united_CSV['problem'] == problem)]\n",
        "\n",
        "  for j, solver_sigma in enumerate(solvers_sigmas):\n",
        "\n",
        "    # Filter the data for the current problem and solver_sigma\n",
        "    solverSigma_filtered_data = problem_filtered_data[(problem_filtered_data['solver_sigma']==solver_sigma)]\n",
        "\n",
        "    for k, seed in enumerate(seeds):\n",
        "\n",
        "      # Filter the data for the current problem and solver_sigma and seed\n",
        "      seed_filtered_data = solverSigma_filtered_data[(solverSigma_filtered_data['seed'] == seed)]\n",
        "\n",
        "      # Check if the filtered data is empty\n",
        "      if seed_filtered_data.empty:\n",
        "        print(f\"No data for problem={problem}, solver_sigma={solver_sigma}, seed={seed}\")\n",
        "        continue\n",
        "\n",
        "      sorted_filtered_data = seed_filtered_data.sort_values('evals', ascending=True)\n",
        "      if objective == 'minimize':\n",
        "        for ii, row in sorted_filtered_data.iterrows():\n",
        "          if row['best_fitness'] <= current_problem_best_fitness_percentile:\n",
        "            current_best_fitness_percentile_evals = row['evals']\n",
        "            break\n",
        "      elif objective == 'maximize':\n",
        "        for ii, row in sorted_filtered_data.iterrows():\n",
        "          if row['best_fitness'] >= current_problem_best_fitness_percentile:\n",
        "            current_best_fitness_percentile_evals = row['evals']\n",
        "            break\n",
        "      else:\n",
        "        raise ValueError('\\\"task_objective\\\" can be only \\\"minimize\\\" or \\\"maximize\\\"')\n",
        "\n",
        "      # Store rankings obtained for each tuple\n",
        "      index = solvers_sigmas.index(solver_sigma)\n",
        "      solvers_sigmas__first_eval_to_hit_threshold[index].append(current_best_fitness_percentile_evals)\n",
        "\n",
        "# Create the boxplot for the current problem\n",
        "plt.figure()\n",
        "bp = plt.boxplot(solvers_sigmas__first_eval_to_hit_threshold, patch_artist=True, vert=False, labels=solvers_sigmas)\n",
        "\n",
        "# Save data for LaTeX plots\n",
        "data_to_plot_transposed = list(map(list, zip(*solvers_sigmas__first_eval_to_hit_threshold)))\n",
        "df = pd.DataFrame(data_to_plot_transposed, columns=solvers_sigmas)\n",
        "df.to_csv(\"LaTeX/\" + experiment_name + \"/\" + \"AAA_\" + experiment_name + \"_Efficiency_percentile-\" + str(efficiency_percentile_reference) + '.txt', sep='\\t', index=False)\n",
        "\n",
        "# Set the colors of the boxplot using the color map\n",
        "for patch, color in zip(bp['boxes'], color_map.colors[:len(solvers_sigmas)]):\n",
        "  patch.set_facecolor(color)\n",
        "\n",
        "# Saving image\n",
        "plt.savefig(\"Figures/\" + experiment_name + \"/\" + experiment_name + \"_Efficiency_percentile-\" + str(efficiency_percentile_reference) + '.png', bbox_inches='tight', transparent=False, dpi=600)\n",
        "\n",
        "# Display image\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RuCnB6gW_31i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Mean NER vs. genotype size (i.e., \"p\") plots\n",
        "\n",
        "# Rank (solver, sigma, seed) tuples by their effectiveness\n",
        "effectiveness_ranking = np.full((len(problems), len(solvers_sigmas_seeds)), '', dtype=object)\n",
        "\n",
        "mean_NER = pd.DataFrame(index=problems, columns=solvers_sigmas)\n",
        "\n",
        "# Add a column containing the \"genotype_size\" for each \"problem\"\n",
        "genotype_size_series = last_evals_df.groupby('problem')['genotype_size'].first()\n",
        "mean_NERs = pd.concat([genotype_size_series, mean_NER], axis=1)\n",
        "\n",
        "for i, problem in enumerate(problems):\n",
        "\n",
        "  filtered_data = last_evals_df[last_evals_df['problem']==problem]\n",
        "\n",
        "  objective = filtered_data['objective'].iloc[0]\n",
        "\n",
        "  # Check if is a max or min problem\n",
        "  if objective == 'minimize':\n",
        "    ascending = True\n",
        "  elif objective == 'maximize':\n",
        "    ascending = False\n",
        "  else:\n",
        "    raise ValueError('\\\"task_objective\\\" can be only \\\"minimize\\\" or \\\"maximize\\\"')\n",
        "\n",
        "  # Sort data\n",
        "  sorted_data = filtered_data.sort_values('best_fitness', ascending=ascending)\n",
        "\n",
        "  # Store rankings on the fixed problem obtained by each cuple (solver, sigma)\n",
        "  solvers_sigmas__rankings = [[] for _ in range(len(solvers_sigmas))]\n",
        "\n",
        "  for j in range(len(solvers_sigmas_seeds)):\n",
        "\n",
        "    # Rank (solver, sigma, seed) tuples by their effectiveness\n",
        "    solver_sigma_seed = sorted_data['solver_sigma_seed'].iloc[j]\n",
        "    effectiveness_ranking[i][j] = solver_sigma_seed\n",
        "\n",
        "    solver_sigma = filtered_data[filtered_data['solver_sigma_seed'] == solver_sigma_seed]['solver_sigma'].iloc[0]\n",
        "\n",
        "    # Store rankings obtained for each tuple\n",
        "    index = solvers_sigmas.index(solver_sigma)\n",
        "    solvers_sigmas__rankings[index].append(j + 1)\n",
        "\n",
        "  for k, solver_sigma in enumerate(solvers_sigmas):\n",
        "    current_mean_rank = statistics.mean(solvers_sigmas__rankings[k])\n",
        "    current_normalized_mean_rank = current_mean_rank / (len(solvers_sigmas) * len(seeds))\n",
        "    mean_NERs.loc[problem, solver_sigma] = current_normalized_mean_rank\n",
        "\n",
        "# Save a .xlsx with mean NER and p for all problems\n",
        "mean_NERs.to_excel(\"XLSX Files/\" + experiment_name + \"/\" + experiment_name + \"_meanNER-vs-p.xlsx\")\n",
        "\n",
        "# Compute the mean NER for fixed values of p\n",
        "mean_NERs_sorted = mean_NERs.sort_values(by='genotype_size')\n",
        "mean_NERs_grouped = mean_NERs_sorted.groupby(\"genotype_size\").mean().reset_index()\n",
        "# save results for LaTeX plots\n",
        "mean_NERs_grouped.to_csv(\"LaTeX/\" + experiment_name + \"/\" + \"AAA_\" + experiment_name + \"_meanNER-vs-p\" + '.txt', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "3v7g65cO6P2C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}